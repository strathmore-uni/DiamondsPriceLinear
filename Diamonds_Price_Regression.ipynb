{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz+PON9IdHTKNUZdU5SALG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/strathmore-uni/DiamondsPriceLinear/blob/main/Diamonds_Price_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YHKdv2VKqBw",
        "outputId": "3211f233-4adb-4b11-b597-5faa94f14da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insight 1: Correlation of numerical features with 'price':\n",
            " price    1.000000\n",
            "carat    0.921592\n",
            "x        0.887231\n",
            "z        0.868206\n",
            "y        0.867864\n",
            "table    0.127245\n",
            "depth   -0.010729\n",
            "Name: price, dtype: float64\n",
            "\n",
            "Insight 2: Price distribution histogram saved as 'price_distribution.png' (for visualization in your report).\n",
            "\n",
            "Insight 3: Median Price by 'cut' (Order of median prices):\n",
            " cut\n",
            "Fair         3282.0\n",
            "Premium      3182.0\n",
            "Good         3050.5\n",
            "Very Good    2647.0\n",
            "Ideal        1809.5\n",
            "Name: price, dtype: float64\n",
            "\n",
            "DataFrame 'diamonds_model' created with 12500 records and saved as 'diamonds_model.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# --- Q1: Download and Upload the Diamonds Dataset ---\n",
        "# Assuming 'diamonds.csv' is already uploaded to your Colab environment.\n",
        "df = pd.read_csv('diamonds.csv')\n",
        "\n",
        "# --- Q2: Data Cleaning ---\n",
        "# 1. Drop the first unnamed index column (if it exists)\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# 2. Drop rows where 'x', 'y', 'z' (dimensions), 'carat', or 'price' are zero/invalid.\n",
        "df_cleaned = df[~((df['x']==0) | (df['y']==0) | (df['z']==0) | (df['carat']==0) | (df['price']==0))].copy()\n",
        "\n",
        "# --- Q2: Exploratory Data Analysis (3 Insights) ---\n",
        "\n",
        "# Insight 1: Correlation of numerical features with 'price'\n",
        "numeric_df = df_cleaned.select_dtypes(include=np.number)\n",
        "correlation_matrix = numeric_df.corr()\n",
        "price_correlations = correlation_matrix['price'].sort_values(ascending=False)\n",
        "print(\"Insight 1: Correlation of numerical features with 'price':\\n\", price_correlations)\n",
        "\n",
        "# Insight 2: Distribution of 'price' (Histogram)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_cleaned['price'], bins=50, kde=True)\n",
        "plt.title('Distribution of Diamond Prices')\n",
        "plt.xlabel('Price (USD)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('price_distribution.png')\n",
        "plt.close()\n",
        "print(\"\\nInsight 2: Price distribution histogram saved as 'price_distribution.png' (for visualization in your report).\")\n",
        "\n",
        "# Insight 3: Median Price by 'cut' quality\n",
        "cut_median_price = df_cleaned.groupby('cut')['price'].median().sort_values(ascending=False)\n",
        "print(\"\\nInsight 3: Median Price by 'cut' (Order of median prices):\\n\", cut_median_price)\n",
        "\n",
        "\n",
        "# --- Q2: Create Sample for Modelling ---\n",
        "sample_size = 12500\n",
        "diamonds_model = df_cleaned.sample(n=sample_size, random_state=42).copy()\n",
        "\n",
        "# Save the sampled data (optional, but good practice for consistency)\n",
        "diamonds_model.to_csv('diamonds_model.csv', index=False)\n",
        "print(f\"\\nDataFrame 'diamonds_model' created with {len(diamonds_model)} records and saved as 'diamonds_model.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sampled data\n",
        "diamonds_model = pd.read_csv('diamonds_model.csv')\n",
        "model_results = {}\n",
        "\n",
        "# --- Feature Engineering and Data Preparation for Q3, Q5 ---\n",
        "\n",
        "# 1. One-Hot Encode Categorical Variables (dropping one level per feature to avoid multicollinearity)\n",
        "diamonds_model_encoded = pd.get_dummies(diamonds_model, columns=['cut', 'color', 'clarity'], drop_first=True)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = diamonds_model_encoded.drop('price', axis=1)\n",
        "y = diamonds_model_encoded['price']\n",
        "\n",
        "# 2. Split the data (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Standardization (Scaling the features)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# --- Q3: Train and Verify Linear Regression Model ---\n",
        "lr_model_q3 = LinearRegression()\n",
        "lr_model_q3.fit(X_train_scaled, y_train)\n",
        "y_pred_q3 = lr_model_q3.predict(X_test_scaled)\n",
        "\n",
        "# Verification\n",
        "r2_q3 = r2_score(y_test, y_pred_q3)\n",
        "mae_q3 = mean_absolute_error(y_test, y_pred_q3)\n",
        "mse_q3 = mean_squared_error(y_test, y_pred_q3)\n",
        "model_results['Q3_LR_All_Features'] = {'R2': r2_q3, 'MAE': mae_q3, 'MSE': mse_q3}\n",
        "\n",
        "print(\"--- Question 3: Linear Regression on All Features Results ---\")\n",
        "print(f\"R-squared (R2): {r2_q3:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_q3:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saIVq0BQK17-",
        "outputId": "f776e497-f5c7-4a17-bb60-b395f113a3e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Question 3: Linear Regression on All Features Results ---\n",
            "R-squared (R2): 0.9281\n",
            "Mean Absolute Error (MAE): $710.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Q4: PCA and Linear Regression on 2 Features ---\n",
        "\n",
        "# 1. Select Continuous Features\n",
        "continuous_features = ['carat', 'x', 'y', 'z', 'table', 'depth']\n",
        "X_cont = diamonds_model[continuous_features]\n",
        "\n",
        "# 2. Standardize Continuous Features\n",
        "scaler_pca = StandardScaler()\n",
        "X_cont_scaled = scaler_pca.fit_transform(X_cont)\n",
        "\n",
        "# 3. Apply PCA to select 2 components\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_cont_scaled)\n",
        "X_pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
        "y_pca = diamonds_model['price']\n",
        "\n",
        "# 4. Split PCA data\n",
        "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(X_pca_df, y_pca, test_size=0.3, random_state=42)\n",
        "\n",
        "# 5. Train Linear Regression Model on PCA components\n",
        "lr_model_q4 = LinearRegression()\n",
        "lr_model_q4.fit(X_pca_train, y_pca_train)\n",
        "y_pred_q4 = lr_model_q4.predict(X_pca_test)\n",
        "\n",
        "# Verification\n",
        "r2_q4 = r2_score(y_pca_test, y_pred_q4)\n",
        "mae_q4 = mean_absolute_error(y_pca_test, y_pred_q4)\n",
        "mse_q4 = mean_squared_error(y_pca_test, y_pred_q4)\n",
        "model_results['Q4_LR_PCA_2_Features'] = {'R2': r2_q4, 'MAE': mae_q4, 'MSE': mse_q4}\n",
        "\n",
        "print(\"\\n--- Question 4: PCA and Linear Regression on 2 Features Results ---\")\n",
        "print(f\"R-squared (R2): {r2_q4:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_q4:.2f}\")\n",
        "print(f\"Variance explained by PC1 and PC2: {pca.explained_variance_ratio_.sum():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHc2wKfGMsk7",
        "outputId": "29b03c36-b8f8-4d8b-e11b-c2ef6399d86a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Question 4: PCA and Linear Regression on 2 Features Results ---\n",
            "R-squared (R2): 0.8077\n",
            "Mean Absolute Error (MAE): $1276.92\n",
            "Variance explained by PC1 and PC2: 0.8638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: X_train_scaled, X_test_scaled, y_train, y_test from Step 2 are used here.\n",
        "alpha = 1.0 # Common alpha value for demonstration\n",
        "\n",
        "# --- Q5: Lasso Regression ---\n",
        "lasso_model = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
        "lasso_model.fit(X_train_scaled, y_train)\n",
        "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
        "\n",
        "# Verification\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
        "model_results['Q5_Lasso_All_Features'] = {'R2': r2_lasso, 'MAE': mae_lasso, 'MSE': mse_lasso}\n",
        "\n",
        "print(\"\\n--- Question 5: Lasso Regression Results (alpha=1.0) ---\")\n",
        "print(f\"R-squared (R2): {r2_lasso:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_lasso:.2f}\")\n",
        "\n",
        "# --- Q5: Ridge Regression ---\n",
        "ridge_model = Ridge(alpha=alpha, random_state=42)\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
        "\n",
        "# Verification\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "model_results['Q5_Ridge_All_Features'] = {'R2': r2_ridge, 'MAE': mae_ridge, 'MSE': mse_ridge}\n",
        "\n",
        "print(\"\\n--- Question 5: Ridge Regression Results (alpha=1.0) ---\")\n",
        "print(f\"R-squared (R2): {r2_ridge:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_ridge:.2f}\")\n",
        "\n",
        "\n",
        "# --- Q6: Model Comparison ---\n",
        "df_results = pd.DataFrame.from_dict(model_results, orient='index')\n",
        "df_results.to_csv('model_comparison_results.csv', index_label='Model')\n",
        "\n",
        "print(\"\\n--- Question 6: All Model Comparison Summary ---\")\n",
        "print(df_results)\n",
        "print(\"\\nFull comparison table saved to 'model_comparison_results.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dV9B1CqMvdx",
        "outputId": "904166f0-6713-4f0f-ac9e-155591c69e67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Question 5: Lasso Regression Results (alpha=1.0) ---\n",
            "R-squared (R2): 0.9279\n",
            "Mean Absolute Error (MAE): $710.37\n",
            "\n",
            "--- Question 5: Ridge Regression Results (alpha=1.0) ---\n",
            "R-squared (R2): 0.9281\n",
            "Mean Absolute Error (MAE): $710.96\n",
            "\n",
            "--- Question 6: All Model Comparison Summary ---\n",
            "                             R2          MAE           MSE\n",
            "Q3_LR_All_Features     0.928104   710.655207  1.170727e+06\n",
            "Q4_LR_PCA_2_Features   0.807690  1276.923613  3.131498e+06\n",
            "Q5_Lasso_All_Features  0.927910   710.373715  1.173885e+06\n",
            "Q5_Ridge_All_Features  0.928075   710.955195  1.171198e+06\n",
            "\n",
            "Full comparison table saved to 'model_comparison_results.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "arEou0hVMzBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}